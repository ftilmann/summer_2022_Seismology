{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from snr.calc_snr import str2snr_strategy\n",
    "from dataset_creation.noisy_dataset import create_single_noisy_version\n",
    "from dataset_creation.utils import get_n_random_noises\n",
    "from utils.common import assert_path_exists"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create a Noisy Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Requirements And Configuration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What is your user root directory?  (`/home/<username>/` on linux machines e.g.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "USER_ROOT_DIR='/home/moshe/'\n",
    "assert_path_exists(path_str=USER_ROOT_DIR, name='USER_ROOT_DIR')\n",
    "USER_ROOT_DIR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What is the root folder of your datasets?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATASETS_ROOT_DIR= os.path.join(USER_ROOT_DIR,'datasets/GFZ/')\n",
    "assert_path_exists(path_str=DATASETS_ROOT_DIR, name='DATASETS_ROOT_DIR')\n",
    "DATASETS_ROOT_DIR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The generated noisy traces should be a synthetic version of traces taken from the following dataset ('ethz', 'geofon'):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATASETS_ORIGINS = ['ethz', 'geofon']\n",
    "dataset_origin = 'ethz'\n",
    "assert dataset_origin in DATASETS_ORIGINS, f'Expected dataset one of {DATASETS_ORIGINS}. Got {dataset_origin}.'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_SAMPLES=3001                    # Trace sample length - If the dataset is built for phasenet: 3001 If it is for EQTransformer: 6000\n",
    "NUM_NOISY_VERSIONS_PER_TRACE=1      # How many noisy versions to synthesize using a single real trace\n",
    "DESIRED_SNR=7                      # What SNR level should the noisy synthesized trace be\n",
    "SAMPLING_RATE=100                   # Sampling Rate - PhaseNet and EQTransformer expect 100Hz\n",
    "NUM_OF_ORIGINAL_TRACES = 2100       # How many original traces to use for the noisy dataset - use slice from the start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SNR_CALC_STRATEGY_STR_ALTERNATIVES = ['energy_ratio', 'max_amplitude_vs_rms_ratio']\n",
    "SNR_CALC_STRATEGY_STR = 'energy_ratio'\n",
    "assert SNR_CALC_STRATEGY_STR in SNR_CALC_STRATEGY_STR_ALTERNATIVES, f'Expected one of {SNR_CALC_STRATEGY_STR_ALTERNATIVES}. Got {SNR_CALC_STRATEGY_STR}'\n",
    "SNR_CALC_STRATEGY=str2snr_strategy(SNR_CALC_STRATEGY_STR)  # Function used to estimate the trace Signal to Noise Ratio(SNR) -  ENERGY_RATIO orMAX_AMPLITUDE_VS_RMS_RATIO\n",
    "SNR_CALC_STRATEGY"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the generated noises should allow shifting experiments they should be longer than the original trace.\n",
    "Define how many 1-second-shifts will the dataset enable."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_SHIFTS=6\n",
    "AUGMENTED_WINDOW_SIZE=NUM_SAMPLES+SAMPLING_RATE*NUM_SHIFTS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Browse The path of the **event** traces that will be used for synthesizing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATASET_PATH= os.path.join(DATASETS_ROOT_DIR, f'noisy_datasets/{dataset_origin}_{NUM_SAMPLES}_sample_joachim_noises_{SNR_CALC_STRATEGY_STR}_snr/')\n",
    "assert_path_exists(path_str=DATASET_PATH, name='DATASET_PATH')\n",
    "DATASET_PATH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Browse The path of the **noise** traces that will be used for synthesizing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NOISES_PATH= os.path.join(DATASETS_ROOT_DIR,'Noises')\n",
    "assert_path_exists(path_str=NOISES_PATH, name='NOISES_PATH')\n",
    "NOISES_PATH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_traces_path = os.path.join(DATASET_PATH, 'original_dataset.pt')\n",
    "dataset_labels_path = os.path.join(DATASET_PATH, 'original_labels.pt')\n",
    "\n",
    "assert_path_exists(path_str=dataset_traces_path, name='dataset_traces_path')\n",
    "assert_path_exists(path_str=dataset_labels_path, name='dataset_labels_path')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset=torch.load(dataset_traces_path)[:NUM_OF_ORIGINAL_TRACES]\n",
    "labels=torch.load(dataset_labels_path)[:NUM_OF_ORIGINAL_TRACES]\n",
    "\n",
    "num_traces = dataset.shape[0]\n",
    "num_labels = labels.shape[0]\n",
    "num_samples = dataset.shape[-1]\n",
    "\n",
    "assert num_labels==num_traces, f'Expected traces equal num labels.Got {num_traces} traces and {num_labels} labels'\n",
    "assert num_samples==NUM_SAMPLES, f'Expected {NUM_SAMPLES} in each trace. Got {num_samples}.'\n",
    "\n",
    "print(f'Loaded {num_traces} traces and corresponding labels.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a Noisy Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "noised_traces_list, noised_traces_labels_list, augmented_noise_traces_list, factors_list, indices_not_used_list = [],[],[],[], []\n",
    "pbar = tqdm(range(NUM_NOISY_VERSIONS_PER_TRACE))\n",
    "for i in pbar:\n",
    "    # prepare full noises traces\n",
    "    augmented_noise_traces_created: torch.tensor = get_n_random_noises(num_noises=num_traces, desired_window_size=AUGMENTED_WINDOW_SIZE, noises_path=NOISES_PATH, force_resample=True, filename='aaa', sampling_rate=SAMPLING_RATE, silent_exception_prints=True).squeeze()\n",
    "\n",
    "    version_noised_traces, version_labels, version_full_noise_traces, version_factors, version_not_included_indices =  create_single_noisy_version(original_traces=dataset, original_labels=labels, augmented_noise_traces=augmented_noise_traces_created, desired_snr=DESIRED_SNR, snr_strategy=SNR_CALC_STRATEGY)\n",
    "    noised_traces_list.append(version_noised_traces)\n",
    "    noised_traces_labels_list.append(version_labels.unsqueeze(dim=1))\n",
    "    augmented_noise_traces_list.append(version_full_noise_traces)\n",
    "    factors_list.append(version_factors.unsqueeze(dim=1))\n",
    "    indices_not_used_list.extend(version_not_included_indices)\n",
    "    pbar.set_description(f'Lists len {len(noised_traces_list), len(noised_traces_labels_list), len(augmented_noise_traces_list), len(factors_list)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "noised_traces = torch.vstack(noised_traces_list)\n",
    "noised_traces_labels = torch.vstack(noised_traces_labels_list).squeeze()\n",
    "augmented_noise_traces = torch.vstack(augmented_noise_traces_list)\n",
    "noising_factors = torch.vstack(factors_list).squeeze()\n",
    "indices_not_used = torch.tensor(list(set(indices_not_used_list)))\n",
    "noised_traces.shape, noised_traces_labels.shape, augmented_noise_traces.shape, noising_factors.shape, indices_not_used.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Noisy Indices To Files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "noisy_dataset_path = os.path.join(DATASET_PATH,f'noisy_dataset_snr_{DESIRED_SNR}')\n",
    "assert_path_exists(path_str=noisy_dataset_path, name='noisy_dataset_path')\n",
    "noisy_dataset_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(noised_traces, os.path.join(noisy_dataset_path, 'traces.pt'))\n",
    "torch.save(augmented_noise_traces, os.path.join(noisy_dataset_path, 'full_noise_traces.pt'))\n",
    "torch.save(noised_traces_labels, os.path.join(noisy_dataset_path, 'labels.pt'))\n",
    "torch.save(noising_factors, os.path.join(noisy_dataset_path, 'factors.pt'))\n",
    "torch.save(indices_not_used, os.path.join(noisy_dataset_path,'indices_not_used'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot Noising Example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "idx = 6\n",
    "trace  = noised_traces[idx]\n",
    "label  = noised_traces_labels[idx]\n",
    "factor = noising_factors[idx]\n",
    "noise = augmented_noise_traces[idx, :, :trace.shape[-1] ]\n",
    "\n",
    "fig, (ax_orig,ax_noise, ax_noised) = plt.subplots(1,3,figsize=(20,8), sharey='all')\n",
    "\n",
    "ax_orig.plot((trace - factor * noise)[0]);\n",
    "ax_orig.vlines(x=label, ymin=-1, ymax=1,  label='Onset', linestyles='dashed');\n",
    "ax_orig.set_title('Original Trace')\n",
    "ax_noise.plot(factor*noise[0]);\n",
    "ax_noise.set_title('Noise added')\n",
    "ax_noised.plot(trace[0]);\n",
    "ax_noised.set_title('Noised Trace')\n",
    "\n",
    "ax_noised.vlines(x=label, ymin=-1, ymax=1,  label='Onset', linestyles='dashed');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A Unified Version of The Noisy Datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For metrics benchmark it is preferred to create several SNR datasets using the same noises. For each SNR, a single noisy version is created."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, prepare the noise that will be used for all SNR levels."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# prepare full noises traces\n",
    "augmented_noise_traces_created: torch.tensor = get_n_random_noises(num_noises=num_traces, desired_window_size=AUGMENTED_WINDOW_SIZE, noises_path=NOISES_PATH, force_resample=True, filename='aaa', sampling_rate=SAMPLING_RATE, silent_exception_prints=True).squeeze()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "desired_snr_list = list(range(2,11))\n",
    "noisy_dataset_paths = {}\n",
    "for desired_snr in desired_snr_list:\n",
    "    noisy_dataset_path = os.path.join(DATASET_PATH,f'noisy_dataset_snr_{desired_snr}')\n",
    "    assert_path_exists(path_str=noisy_dataset_path, name='noisy_dataset_path')\n",
    "    noisy_dataset_paths[desired_snr] = noisy_dataset_path\n",
    "\n",
    "pbar = tqdm(desired_snr_list)\n",
    "for desired_snr in pbar:\n",
    "    noised_traces, noised_traces_labels, full_noise_traces_used, factors, indices_not_used_list =  create_single_noisy_version(original_traces=dataset, original_labels=labels, augmented_noise_traces=augmented_noise_traces_created, desired_snr=desired_snr, snr_strategy=SNR_CALC_STRATEGY)\n",
    "\n",
    "    indices_not_used = torch.tensor(list(set(indices_not_used_list)))\n",
    "    noisy_dataset_path = noisy_dataset_paths[desired_snr]\n",
    "    torch.save(noised_traces, os.path.join(noisy_dataset_path, 'traces.pt'))\n",
    "    torch.save(augmented_noise_traces, os.path.join(noisy_dataset_path, 'full_noise_traces.pt'))\n",
    "    torch.save(noised_traces_labels, os.path.join(noisy_dataset_path, 'labels.pt'))\n",
    "    torch.save(noising_factors, os.path.join(noisy_dataset_path, 'factors.pt'))\n",
    "    torch.save(indices_not_used, os.path.join(noisy_dataset_path,'indices_not_used'))\n",
    "    pbar.set_description(f'SNR {desired_snr}: {noised_traces.shape[0]} noised traces created and saved.')\n",
    "    del noised_traces, noised_traces_labels, full_noise_traces_used, factors, indices_not_used_list , indices_not_used"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa76d2c83586c95486e2cc3c656ad2d093b47aefbf53fc633acb9a860f5157ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
