{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model Retraining"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preliminaries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# general\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# wandb - hyperparameter sweep and Train monitoring\n",
    "import wandb\n",
    "#torch - computing and machine learning libraries\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "# seisbench\n",
    "import seisbench.models as sbm\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# seisynth\n",
    "from utils.common import load_dataset_and_labels, load_pretrained_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Possible values\n",
    "DATASETS_ORIGINS = ['ethz', 'geofon']\n",
    "SBM_CLASSES= [sbm.PhaseNet, sbm.EQTransformer]\n",
    "MODEL_TO_NUM_SAMPLES = {sbm.EQTransformer:6000, sbm.PhaseNet: 3001}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataset_origin = 'geofon'\n",
    "assert dataset_origin in DATASETS_ORIGINS, f'Expected dataset one of {DATASETS_ORIGINS}. Got {dataset_origin}.'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "seisbench.models.phasenet.PhaseNet"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBM_CLASS= sbm.PhaseNet\n",
    "assert SBM_CLASS in SBM_CLASSES\n",
    "SBM_CLASS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "3001"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_SAMPLES=MODEL_TO_NUM_SAMPLES[SBM_CLASS]\n",
    "NUM_SAMPLES"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "NUM_SHIFTS=6\n",
    "SAMPLE_RATE=100\n",
    "LARGE_ERROR_THRESHOLD_SECONDS=1\n",
    "LARGE_ERROR_THRESHOLD_SAMPLES=LARGE_ERROR_THRESHOLD_SECONDS*SAMPLE_RATE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[2, 3, 4, 5, 6, 7, 8, 9, 10]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SYNTHESIZED_SNR_LIST= list(range(2,11))\n",
    "SYNTHESIZED_SNR_LIST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def assert_path_exists(path_str: str, name: str=''):\n",
    "    assert os.path.exists(path_str), f'{name} {path_str} does not exist'\n",
    "\n",
    "@torch.no_grad()\n",
    "def standardize(trace: torch.tensor):\n",
    "    m = trace.mean(dim=-1, keepdim=True).unsqueeze(dim=0)\n",
    "    std = trace.std(dim=-1, keepdim=True).unsqueeze(dim=0)\n",
    "    trace = trace.unsqueeze(dim=0) if trace.dim() == 1 else trace\n",
    "    standardized = torch.stack([(trace[ch] - m[0, ch]) / std[0, ch] for ch in range(trace.shape[0])], dim=0)\n",
    "    assert standardized.shape == trace.shape, f'Standardization should not change shape. Got {standardized.shape}'\n",
    "    return standardized"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_PATH=f'/home/moshe/datasets/GFZ/noisy_datasets/{dataset_origin}_trainset_{NUM_SAMPLES}_sample_joachim_noises_energy_ratio_snr/'\n",
    "assert_path_exists(path_str=DATASET_PATH, name='DATASET_PATH')\n",
    "DATASET_PATH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "['/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_2',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_3',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_4',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_5',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_6',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_7',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_8',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_9',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_10']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOISY_DATA_PATH_LIST = [os.path.join(DATASET_PATH, f'noisy_small_dataset_snr_{synthesized_snr}') for synthesized_snr in SYNTHESIZED_SNR_LIST]\n",
    "for p in NOISY_DATA_PATH_LIST:\n",
    "    assert_path_exists(path_str=p)\n",
    "NOISY_DATA_PATH_LIST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Pretrained Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the model with the pretrained weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with <class 'seisbench.models.phasenet.PhaseNet'> on GEOFON\n",
      "Load <class 'seisbench.models.phasenet.PhaseNet'> pretrained weights\n",
      "<class 'seisbench.models.phasenet.PhaseNet'> pretrained keys ['ethz', 'geofon', 'instance', 'iquique', 'lendb', 'neic', 'original', 'scedc', 'stead']\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = load_pretrained_model(model_class=SBM_CLASS, dataset_trained_on=dataset_origin)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save a copy for retraining. One model will be trained and the other one will keep the current weights for benchmarking on specific examples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# reloading because I cannot torch clone. Seisbench models are not nn.Module :(\n",
    "# retraining_model = load_pretrained_model(model_class=SBM_CLASS, dataset_trained_on=dataset_origin)\n",
    "retraining_model = sbm.PhaseNet(phases=\"PSN\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "PhaseNet(\n  (inc): Conv1d(3, 8, kernel_size=(7,), stride=(1,), padding=same)\n  (in_bn): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (down_branch): ModuleList(\n    (0): ModuleList(\n      (0): Conv1d(8, 8, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n      (1): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Conv1d(8, 8, kernel_size=(7,), stride=(4,), padding=(3,), bias=False)\n      (3): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): ModuleList(\n      (0): Conv1d(8, 16, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n      (1): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Conv1d(16, 16, kernel_size=(7,), stride=(4,), bias=False)\n      (3): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): ModuleList(\n      (0): Conv1d(16, 32, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n      (1): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Conv1d(32, 32, kernel_size=(7,), stride=(4,), bias=False)\n      (3): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): ModuleList(\n      (0): Conv1d(32, 64, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n      (1): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Conv1d(64, 64, kernel_size=(7,), stride=(4,), bias=False)\n      (3): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (4): ModuleList(\n      (0): Conv1d(64, 128, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n      (1): BatchNorm1d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (2): None\n      (3): None\n    )\n  )\n  (up_branch): ModuleList(\n    (0): ModuleList(\n      (0): ConvTranspose1d(128, 64, kernel_size=(7,), stride=(4,), bias=False)\n      (1): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Conv1d(128, 64, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n      (3): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): ModuleList(\n      (0): ConvTranspose1d(64, 32, kernel_size=(7,), stride=(4,), bias=False)\n      (1): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Conv1d(64, 32, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n      (3): BatchNorm1d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): ModuleList(\n      (0): ConvTranspose1d(32, 16, kernel_size=(7,), stride=(4,), bias=False)\n      (1): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Conv1d(32, 16, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n      (3): BatchNorm1d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): ModuleList(\n      (0): ConvTranspose1d(16, 8, kernel_size=(7,), stride=(4,), bias=False)\n      (1): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Conv1d(16, 8, kernel_size=(7,), stride=(1,), padding=same, bias=False)\n      (3): BatchNorm1d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (out): Conv1d(8, 3, kernel_size=(1,), stride=(1,), padding=same)\n  (softmax): Softmax(dim=1)\n)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model.eval()\n",
    "# retraining_model.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Datasets\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have 4 datasets:\n",
    "1. original_dataset - ETHZ/GEOFON original traces filtered to have high estimated SNR - more than 20dB\n",
    "2. le_original_dataset - A subset of the original_dataset (high SNR traces) that the pretrained model had a large picking error.\n",
    "3. noised_dataset - Traces taken from the original dataset and merged with noise traces such that the resulting trace is a 10 dB SNR trace.\n",
    "4. le_noised_dataset -  A subset of the noised_dataset that the pretrained model had a large picking error."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Noisy Traces"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load synthetic noisy traces with various SNR levels and mix them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "['/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_2/traces.pt',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_3/traces.pt',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_4/traces.pt',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_5/traces.pt',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_6/traces.pt',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_7/traces.pt',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_8/traces.pt',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_9/traces.pt',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_10/traces.pt']"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOISY_DATA_PATH_TRACES_LIST = [os.path.join(ndpl, 'traces.pt') for ndpl in NOISY_DATA_PATH_LIST]\n",
    "for p in NOISY_DATA_PATH_TRACES_LIST:\n",
    "    assert_path_exists(path_str=p)\n",
    "NOISY_DATA_PATH_TRACES_LIST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "['/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_2/labels.pt',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_3/labels.pt',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_4/labels.pt',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_5/labels.pt',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_6/labels.pt',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_7/labels.pt',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_8/labels.pt',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_9/labels.pt',\n '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/noisy_small_dataset_snr_10/labels.pt']"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOISY_DATA_PATH_LABELS_LIST = [os.path.join(ndpl, 'labels.pt') for ndpl in NOISY_DATA_PATH_LIST]\n",
    "for p in NOISY_DATA_PATH_LABELS_LIST:\n",
    "    assert_path_exists(path_str=p)\n",
    "NOISY_DATA_PATH_LABELS_LIST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# noised_dataset_path= os.path.join(NOISY_DATA_PATH, 'traces.pt')\n",
    "# assert_path_exists(path_str=noised_dataset_path)\n",
    "# noised_labels_path= os.path.join(NOISY_DATA_PATH, 'labels.pt')\n",
    "# assert_path_exists(path_str=noised_labels_path)\n",
    "# noised_dataset_path, noised_labels_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traces_list 1 labels_list 1\n",
      "traces_list 2 labels_list 2\n",
      "traces_list 3 labels_list 3\n",
      "traces_list 4 labels_list 4\n",
      "traces_list 5 labels_list 5\n",
      "traces_list 6 labels_list 6\n",
      "traces_list 7 labels_list 7\n",
      "traces_list 8 labels_list 8\n",
      "traces_list 9 labels_list 9\n",
      "traces shape torch.Size([9000, 3, 3001]) labels_list torch.Size([9000])\n"
     ]
    }
   ],
   "source": [
    "def load_dataset_from_tensors(traces_path_list: list[torch.tensor], labels_path_list: list[torch.tensor], indices_to_use: list[int]=[]):\n",
    "    traces_list, labels_list = [], []\n",
    "    for tp, lp in zip(traces_path_list, labels_path_list):\n",
    "        traces,labels = load_dataset_and_labels(dataset_path=tp, labels_path=lp)\n",
    "        if indices_to_use:\n",
    "            traces, labels = traces[indices_to_use], labels[indices_to_use]\n",
    "        traces_list.append(traces)\n",
    "        labels_list.append(labels.unsqueeze(dim=1))\n",
    "        print(f'traces_list {len(traces_list)} labels_list {len(labels_list)}')\n",
    "\n",
    "\n",
    "    traces = torch.vstack(traces_list)\n",
    "    labels = torch.vstack(labels_list).squeeze()\n",
    "    print(f'traces shape {traces.shape} labels_list {labels.shape}')\n",
    "    return traces, labels\n",
    "\n",
    "noised_dataset, noised_labels = load_dataset_from_tensors(traces_path_list=NOISY_DATA_PATH_TRACES_LIST, labels_path_list=NOISY_DATA_PATH_LABELS_LIST, indices_to_use=list(range(1000)))\n",
    "\n",
    "noised_dataset_size = noised_dataset.shape[0]\n",
    "\n",
    "# noised_dataset, noised_labels = load_dataset_and_labels(dataset_path=noised_dataset_path, labels_path=noised_labels_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9000 traces\n"
     ]
    }
   ],
   "source": [
    "print(f'Loaded {noised_dataset_size} traces')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Original Data - Various SNR Levels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following are traces from the original dataset with SNR of all levels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(['/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/traces_geofon_bounds_-20_0.pt',\n  '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/traces_geofon_bounds_0_2.pt',\n  '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/traces_geofon_bounds_2_5.pt',\n  '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/traces_geofon_bounds_5_10.pt',\n  '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/traces_geofon_bounds_10_20.pt',\n  '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/traces_geofon_bounds_20_100.pt'],\n ['/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/labels_geofon_bounds_-20_0.pt',\n  '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/labels_geofon_bounds_0_2.pt',\n  '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/labels_geofon_bounds_2_5.pt',\n  '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/labels_geofon_bounds_5_10.pt',\n  '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/labels_geofon_bounds_10_20.pt',\n  '/home/moshe/datasets/GFZ/noisy_datasets/geofon_trainset_3001_sample_joachim_noises_energy_ratio_snr/labels_geofon_bounds_20_100.pt'])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of SNR bin edges to which the traces seperated\n",
    "bounds = [-20, 0, 2, 5, 10, 20, 100]\n",
    "# j=5\n",
    "t_list, l_list = [], []\n",
    "for j in range(len(bounds)-1):\n",
    "    suffix = f'_{dataset_origin}_bounds_{bounds[j]}_{bounds[j+1]}.pt'\n",
    "    t = os.path.join(DATASET_PATH, 'traces' + suffix)\n",
    "    assert_path_exists(path_str=t)\n",
    "    t_list.append(t)\n",
    "    l = os.path.join(DATASET_PATH, 'labels' + suffix)\n",
    "    assert_path_exists(path_str=l)\n",
    "    l_list.append(l)\n",
    "t_list, l_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traces_list 1 labels_list 1\n",
      "traces_list 2 labels_list 2\n",
      "traces_list 3 labels_list 3\n",
      "traces_list 4 labels_list 4\n",
      "traces_list 5 labels_list 5\n",
      "traces_list 6 labels_list 6\n",
      "traces shape torch.Size([1200, 3, 3001]) labels_list torch.Size([1200])\n"
     ]
    }
   ],
   "source": [
    "original_snr_binned_dataset, original_snr_binned_labels = load_dataset_from_tensors(traces_path_list=t_list, labels_path_list=l_list, indices_to_use=list(range(200)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1200 traces\n"
     ]
    }
   ],
   "source": [
    "print(f'Loaded {original_snr_binned_dataset.shape[0]} traces')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make the real data set size equal to the synthetic one and leave the rest for test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([100, 3, 3001]),\n torch.Size([100]),\n torch.Size([1100, 3, 3001]),\n torch.Size([1100]))"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original_snr_binned_dataset, original_snr_binned_labels, original_snr_binned_dataset_left_for_test, original_snr_binned_labels_left_for_test = original_snr_binned_dataset[:noised_dataset_size], original_snr_binned_labels[:noised_dataset_size], original_snr_binned_dataset[noised_dataset_size:], original_snr_binned_labels[noised_dataset_size:]\n",
    "\n",
    "original_snr_binned_dataset, original_snr_binned_labels, original_snr_binned_dataset_left_for_test, original_snr_binned_labels_left_for_test = original_snr_binned_dataset[:100], original_snr_binned_labels[:100], original_snr_binned_dataset[100:], original_snr_binned_labels[100:]\n",
    "\n",
    "\n",
    "original_snr_binned_dataset.shape, original_snr_binned_labels.shape, original_snr_binned_dataset_left_for_test.shape, original_snr_binned_labels_left_for_test.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mix The Datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([9100, 3, 3001]), torch.Size([9100]))"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_dataset = torch.vstack((original_snr_binned_dataset, noised_dataset))\n",
    "mixed_labels = torch.vstack((original_snr_binned_labels.unsqueeze(dim=1), noised_labels.unsqueeze(dim=1))).squeeze()\n",
    "mixed_dataset.shape, mixed_labels.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# le_noised_dataset_path = os.path.join(NOISY_DATA_PATH, f'le_{str(SBM_CLASS)}_dataset.pt')\n",
    "# assert_path_exists(path_str=le_noised_dataset_path)\n",
    "# le_noised_labels_path = os.path.join(NOISY_DATA_PATH, f'le_{str(SBM_CLASS)}_labels.pt')\n",
    "# assert_path_exists(path_str=le_noised_labels_path)\n",
    "# le_noised_dataset_path, le_noised_labels_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# le_noised_dataset, le_noised_labels = load_dataset_and_labels(dataset_path=le_noised_dataset_path, labels_path=le_noised_labels_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# print(f'Loaded {le_noised_dataset.shape[0]} traces')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Arrange Train\\Validation\\Test Sets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "train_dataset_inds, val_dataset_inds, test_dataset_inds = random_split(range(mixed_dataset.shape[0]), [0.85,0.1,0.05], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# train_dataset_inds, val_dataset_inds, test_dataset_inds = random_split(range(original_snr_binned_dataset.shape[0]), [0.85,0.1,0.05], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# train_dataset_inds, val_dataset_inds, test_dataset_inds = random_split(range(noised_dataset.shape[0]), [0.85,0.1,0.05], generator=torch.Generator().manual_seed(42))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# train_dataset, val_dataset, test_dataset = original_snr_binned_dataset[train_dataset_inds], original_snr_binned_dataset[val_dataset_inds], original_snr_binned_dataset[test_dataset_inds]\n",
    "# train_labels, val_labels, test_labels = original_snr_binned_labels[train_dataset_inds], original_snr_binned_labels[val_dataset_inds], original_snr_binned_labels[test_dataset_inds]\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = mixed_dataset[train_dataset_inds], mixed_dataset[val_dataset_inds], mixed_dataset[test_dataset_inds]\n",
    "train_labels, val_labels, test_labels = mixed_labels[train_dataset_inds], mixed_labels[val_dataset_inds], mixed_labels[test_dataset_inds]\n",
    "\n",
    "# train_dataset, val_dataset, test_dataset = noised_dataset[train_dataset_inds], noised_dataset[val_dataset_inds], noised_dataset[test_dataset_inds]\n",
    "# train_labels, val_labels, test_labels = noised_labels[train_dataset_inds], noised_labels[val_dataset_inds], noised_labels[test_dataset_inds]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "val_gen_dataset = original_snr_binned_dataset_left_for_test\n",
    "val_gen_labels = original_snr_binned_labels_left_for_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train set with 7735 traces, validation set with 910 traces and test set with 455 traces.\n"
     ]
    }
   ],
   "source": [
    "print(f'Created train set with {train_dataset.shape[0]} traces, validation set with {val_dataset.shape[0]} traces and test set with {test_dataset.shape[0]} traces.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# raise Exception"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Standardize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# print(train_dataset.std(), train_dataset.mean(),train_dataset.isnan().sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# train_dataset, val_dataset, test_dataset = standardize(train_dataset), standardize(val_dataset), standardize(test_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# print(train_dataset.std(), train_dataset.mean(), train_dataset.isnan().sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# raise Exception"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Custom Datasets/DataLoader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def label_normal_smooth(label):\n",
    "    num_samples = NUM_SAMPLES\n",
    "    sigma = 1000.0\n",
    "    v = torch.arange(num_samples).double()\n",
    "    return (1.0/(sigma*torch.sqrt(2.0* torch.tensor(torch.pi)))) * torch.exp(-0.5*torch.square((v-label)/sigma))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset: torch.tensor, labels: torch.tensor, transform=None, target_transform=None):\n",
    "        self._dataset = dataset\n",
    "        self._labels = labels\n",
    "        assert dataset.dim() == 3, f'Expected 3 dim dataset tensor (#traces,#channels,#samples). Got {dataset.dim()} dims. Shape {dataset.shape} '\n",
    "        assert labels.shape[0] == dataset.shape[0], f'Expected 1 label per trace. Got {labels.shape[0]} for {dataset.shape[0]} traces'\n",
    "        self._len = int(dataset.shape[0])\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        trace = self._dataset[idx]\n",
    "        label = self._labels[idx]\n",
    "        if self.transform:\n",
    "            trace = self.transform(trace)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return trace, label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "trainset = CustomDataset(dataset=train_dataset, labels=train_labels, target_transform=lambda l: (l,label_normal_smooth(l)))\n",
    "valset = CustomDataset(dataset=val_dataset, labels=val_labels, target_transform=lambda l: (l,label_normal_smooth(l)))\n",
    "valgenset = CustomDataset(dataset=val_gen_dataset, labels=val_gen_labels,target_transform=lambda l: (l,label_normal_smooth(l)))\n",
    "testset = CustomDataset(dataset=test_dataset, labels=test_labels, target_transform=lambda l: (l,label_normal_smooth(l)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train set with 7735 traces, validation set with 910 traces and test set with 455 traces.\n"
     ]
    }
   ],
   "source": [
    "print(f'Created train set with {len(trainset)} traces, validation set with {len(valset)} traces and test set with {len(testset)} traces.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Loss Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Taken from Seisbench tutorial notebook \"03a_training_phasenet\"  -  not using it for now - commented out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def loss_fn(y_pred, y_true, eps=1e-5):\n",
    "    # vector cross entropy loss\n",
    "    h = y_true * torch.log(y_pred + eps)\n",
    "\n",
    "    h = h.mean(-1).sum(-1)  # Mean along sample dimension and sum along pick dimension\n",
    "\n",
    "    h = h.mean()  # Mean over batch axis\n",
    "\n",
    "    return -h"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train Loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, large_error_threshold=100):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss = 0.0\n",
    "    large_errors_counter = 0\n",
    "    mean_residual = 0.0\n",
    "    for batch_id, batch in enumerate(dataloader):\n",
    "        trace, (label, label_smoothed) = batch\n",
    "\n",
    "        # print('trace shape', trace.shape, 'label shape', label.shape, 'label_smoothed shape', label_smoothed.shape)\n",
    "\n",
    "        batch_size = trace.shape[0]\n",
    "        # print('batch_size', batch_size)\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        # Fwd pass - outputs the likelihood function\n",
    "        pred_probs = model(trace.double().to(model.device))\n",
    "\n",
    "        if SBM_CLASS == sbm.EQTransformer:\n",
    "            # EQTransformer returns a tuple (N,Z,E)\n",
    "            pred_probs = torch.stack((pred_probs[1],pred_probs[0],pred_probs[2]), dim=0).swapaxes(0,1)\n",
    "        # print('pred_probs shape', pred_probs.shape)\n",
    "\n",
    "\n",
    "        # softargmax\n",
    "        beta = 100.0\n",
    "        softmax = torch.nn.functional.softmax(beta  * pred_probs[:, 0, :], dim=-1)\n",
    "        indices = torch.arange(pred_probs[:, 0, :].shape[-1])\n",
    "        softargmax_preds = torch.sum(torch.mul(indices, softmax), dim=-1)\n",
    "\n",
    "        loss = torch.abs(softargmax_preds - label).mean()\n",
    "\n",
    "        # loss = loss_fn(pred_probs[:,0,:], label_smoothed.double().to(model.device))\n",
    "        # print('loss', loss)\n",
    "        # loss = loss_fn(F.log_softmax(pred_probs[:,0,:], dim=-1), F.log_softmax(label.to(model.device), dim=-1))\n",
    "\n",
    "        prediction = torch.argmax(pred_probs[:, 0, :], dim=-1)\n",
    "        # print('prediction', prediction.shape)\n",
    "        residual = torch.abs(prediction - label.to(model.device))\n",
    "        # print(residual)\n",
    "        mean_residual += float(residual.mean())\n",
    "        # print('mean_residual', mean_residual)\n",
    "        # print(residual > large_error_threshold)\n",
    "        # print(residual[residual > large_error_threshold])\n",
    "        # print((residual > large_error_threshold).sum())\n",
    "        # large_errors_counter += (1 if residual > large_error_threshold else 0)\n",
    "        large_errors_counter += int((residual > large_error_threshold).sum())\n",
    "        # print(large_errors_counter)\n",
    "\n",
    "        # if batch_id == 2:\n",
    "        #     break\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # if batch_id % 100 == 0:\n",
    "        #     loss, current = loss.item(), batch_id * trace.shape[0]\n",
    "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    mean_residual /= num_batches\n",
    "    train_loss /= num_batches\n",
    "\n",
    "    # print(mean_residual)\n",
    "    # print(train_loss)\n",
    "    # raise Exception\n",
    "    return train_loss, mean_residual, large_errors_counter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def test_loop(dataloader, model, loss_fn, large_error_threshold=100):\n",
    "    model.eval()\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "    large_errors_counter = 0\n",
    "    mean_residual = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            trace, (label, label_smoothed) = batch\n",
    "            pred_probs = model(trace.double().to(model.device))\n",
    "            if SBM_CLASS == sbm.EQTransformer:\n",
    "                # EQTransformer returns a tuple (N,Z,E)\n",
    "                pred_probs = torch.stack((pred_probs[1],pred_probs[0],pred_probs[2]), dim=0).swapaxes(0,1)\n",
    "            # Take the maximum of the z channel prediction\n",
    "            loss = loss_fn(pred_probs[:,0,:], label_smoothed.to(model.device))\n",
    "            # loss = loss_fn(F.log_softmax(pred_probs[:,0,:], dim=-1), F.log_softmax(label_smoothed.to(model.device), dim=-1))\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            prediction = torch.argmax(pred_probs[:, 0, :], dim=-1)\n",
    "            residual = float(torch.abs(prediction - label.to(model.device)))\n",
    "            mean_residual += residual\n",
    "            large_errors_counter += (1 if residual > large_error_threshold else 0)\n",
    "\n",
    "    mean_residual /= num_batches\n",
    "    test_loss /= num_batches\n",
    "    return test_loss, mean_residual, large_errors_counter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def train(trainset, valset, valgenset, epochs, learning_rate, batch_size, benchmark_model=None):\n",
    "    # init weights&biases monitoring\n",
    "    wandb.init(project=\"seisynth\", entity=\"moshebeutel\")\n",
    "    wandb.config = {\"learning_rate\": learning_rate, \"epochs\": epochs, \"batch_size\": batch_size}\n",
    "\n",
    "    trained_model = load_pretrained_model(model_class=SBM_CLASS, dataset_trained_on=dataset_origin).double()\n",
    "    train_dataloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_dataloader = DataLoader(valset, batch_size=1, shuffle=False)\n",
    "    valgen_dataloader= DataLoader(valgenset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # Define the train optimizer and optimization criterion\n",
    "    # optimizer = torch.optim.SGD(trained_model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-3)\n",
    "    optimizer = torch.optim.Adam(trained_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # criterion = torch.nn.KLDivLoss(reduction='batchmean', log_target=True)\n",
    "    # criterion = torch.nn.MSELoss()\n",
    "\n",
    "    criterion = loss_fn\n",
    "\n",
    "    # Evaluate the benchmark model on the validation data.\n",
    "    # The benchmark model is not training so it is done once.\n",
    "    if benchmark_model is not None:\n",
    "        benchmark_loss, benchmark_mean_residual, benchmark_large_errors_counter =  test_loop(dataloader=val_dataloader, model=benchmark_model, loss_fn=criterion, large_error_threshold=LARGE_ERROR_THRESHOLD_SAMPLES)\n",
    "        print(f'Benchmark results: loss {benchmark_loss}, Mean Residual {benchmark_mean_residual}, Errors Above {LARGE_ERROR_THRESHOLD_SECONDS} sec. {benchmark_large_errors_counter}')\n",
    "\n",
    "    best_val_mean_residual = 10000\n",
    "\n",
    "    pbar = tqdm(range(epochs))\n",
    "    for t in pbar:\n",
    "        epoch_train_loss, epoch_train_mean_residual, epoch_train_large_errors_counter = train_loop(dataloader=train_dataloader, model=trained_model, loss_fn=criterion , optimizer=optimizer, large_error_threshold=LARGE_ERROR_THRESHOLD_SAMPLES)\n",
    "        epoch_val_loss, epoch_val_mean_residual, epoch_val_large_errors_counter = test_loop(dataloader=val_dataloader, model=trained_model, loss_fn=criterion, large_error_threshold=LARGE_ERROR_THRESHOLD_SAMPLES)\n",
    "        epoch_valgen_loss, epoch_valgen_mean_residual, epoch_valgen_large_errors_counter = test_loop(dataloader=valgen_dataloader, model=trained_model, loss_fn=criterion, large_error_threshold=LARGE_ERROR_THRESHOLD_SAMPLES)\n",
    "\n",
    "        wandb.log({'epoch train loss': epoch_train_loss,\n",
    "                   'epoch_train_mean_residual':epoch_train_mean_residual,\n",
    "                   'epoch_train_large_errors_counter':epoch_train_large_errors_counter,\n",
    "                   'epoch validation loss': epoch_val_loss,\n",
    "                   'epoch_val_mean_residual':epoch_val_mean_residual,\n",
    "                   'epoch_val_large_errors_counter':epoch_val_large_errors_counter,\n",
    "                   'epoch validation gen loss': epoch_valgen_loss,\n",
    "                   'epoch_valgen_mean_residual':epoch_valgen_mean_residual,\n",
    "                   'epoch_valgen_large_errors_counter':epoch_valgen_large_errors_counter})\n",
    "\n",
    "        if epoch_val_mean_residual < best_val_mean_residual:\n",
    "            best_val_mean_residual = epoch_val_mean_residual\n",
    "            trained_model.save(path=f'./mean_residual_{epoch_val_mean_residual}_lr_{learning_rate}_batch_{batch_size}')\n",
    "\n",
    "\n",
    "        pbar.set_description(f'Epoch {t}, train loss {epoch_train_loss}, validation loss {epoch_val_loss}, epoch_val_large_errors_counter {epoch_val_large_errors_counter}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 16"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter Sweep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# sweep_config = {\n",
    "#     'method': 'grid'\n",
    "#     }\n",
    "# parameters_dict = {}\n",
    "#\n",
    "# sweep_config['parameters'] = parameters_dict\n",
    "# metric = {\n",
    "#     'name': 'epoch_val_mean_residual',\n",
    "#     'goal': 'minimize'\n",
    "#     }\n",
    "#\n",
    "# sweep_config['metric'] = metric\n",
    "#\n",
    "# # parameters_dict.update({\n",
    "# #     'epochs': {\n",
    "# #         'value': 50},\n",
    "# #     })\n",
    "#\n",
    "# parameters_dict.update({\n",
    "#       'learning_rate_log': {\n",
    "#           'values': [-7, -6, -5, -4]\n",
    "#       },\n",
    "#       'batch_size': {\n",
    "#           'values': [16, 32, 64, 128]\n",
    "#       }\n",
    "#     })\n",
    "#\n",
    "# def sweep_train(config=None):\n",
    "#\n",
    "#     with wandb.init(config=config):\n",
    "#         config = wandb.config\n",
    "#\n",
    "#         learning_rate = 10 ** config.learning_rate_log\n",
    "#\n",
    "#         batch_size=config.batch_size\n",
    "#         epochs = 13\n",
    "#\n",
    "#         train(trainset=trainset, valset=valset, benchmark_model=None, epochs=epochs, learning_rate=learning_rate, batch_size=batch_size)\n",
    "# sweep_id = wandb.sweep(sweep_config, project=\"seisynth\")\n",
    "# wandb.agent(sweep_id, sweep_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# for (batch_size,lr) in [(64,1e-4), (64, 1e-3)]:\n",
    "#     train(trainset=trainset, valset=valset, benchmark_model=pretrained_model.double(), epochs=15, learning_rate=lr, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Call Train Entry Point"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# train(trainset=trainset, valset=valset, benchmark_model=pretrained_model.double(), epochs=EPOCHS, learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE)\n",
    "# train(trainset=trainset, valset=valset, valgenset=valgenset, epochs=EPOCHS, learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "\n",
    "# # Large Error Traces\n",
    "# original_dataset_path = os.path.join(DATASET_PATH, 'le_original_dataset.pt')\n",
    "# assert_path_exists(path_str=original_dataset_path)\n",
    "# original_labels_path = os.path.join(DATASET_PATH, 'le_original_labels.pt')\n",
    "# assert_path_exists(path_str=original_labels_path)\n",
    "# bounds = [-20, 0, 2, 5, 10, 20, 100]\n",
    "# j=5\n",
    "# suffix = f'_{dataset_origin}_bounds_{bounds[j]}_{bounds[j+1]}.pt'\n",
    "#\n",
    "# original_dataset_path = os.path.join(DATASET_PATH, 'traces' + suffix)\n",
    "# assert_path_exists(path_str=original_dataset_path)\n",
    "# original_labels_path = os.path.join(DATASET_PATH, 'labels' + suffix)\n",
    "# assert_path_exists(path_str=original_labels_path)\n",
    "#\n",
    "# original_dataset, original_labels = load_dataset_and_labels(dataset_path=original_dataset_path, labels_path=original_labels_path)\n",
    "\n",
    "# original_dataset, original_labels = original_snr_binned_dataset_left_for_test, original_snr_binned_labels_left_for_test\n",
    "# original_dataset, original_labels = test_dataset, test_labels\n",
    "#\n",
    "# valset_original = CustomDataset(dataset=original_dataset.float(), labels=original_labels.float(), target_transform=lambda l: (l,label_normal_smooth(l)))\n",
    "#\n",
    "# benchmark_dataloader = DataLoader(valset_original, batch_size=1, shuffle=False)\n",
    "# print(len(valset_original))\n",
    "# criterion = loss_fn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "\n",
    "# benchmark_loss, benchmark_mean_residual, benchmark_large_errors_counter =  test_loop(dataloader=benchmark_dataloader, model=pretrained_model, loss_fn=criterion, large_error_threshold=LARGE_ERROR_THRESHOLD_SAMPLES)\n",
    "#\n",
    "# benchmark_loss, benchmark_mean_residual, benchmark_large_errors_counter, float(benchmark_large_errors_counter) / float(len(benchmark_dataloader))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# retraining_model =  SBM_CLASS.load('/home/moshe/GIT/summer_2022_Seismology/models/GFZ/retrains_on_mixed_real_and_synthetic_datasets/phasenet_geofon/mean_residual_54.69584352631581_lr_0.0001_batch_16')\n",
    "#\n",
    "\n",
    "# trained on mixed  30000 - snr binned and noisy\n",
    "# retraining_model =  SBM_CLASS.load('/home/moshe/GIT/summer_2022_Seismology/models/GFZ/retrains_on_mixed_real_train_and_synthetic_datasets/mean_residual_57.52923886111117_lr_0.0001_batch_16')\n",
    "\n",
    "# trained on real  15000  snr binned only\n",
    "# retraining_model =  SBM_CLASS.load('/home/moshe/GIT/summer_2022_Seismology/notebooks/mean_residual_38.62195977777774_lr_0.0001_batch_16')\n",
    "\n",
    "\n",
    "# trained on  4250 noisy only\n",
    "# retraining_model =  SBM_CLASS.load('/home/moshe/GIT/summer_2022_Seismology/notebooks/mean_residual_44.00933950000001_lr_0.0001_batch_16')\n",
    "\n",
    "\n",
    "# trained on  15000 noisy only  standardize\n",
    "# retraining_model =  SBM_CLASS.load('/home/moshe/GIT/summer_2022_Seismology/notebooks/mean_residual_55.95261939999995_lr_0.0001_batch_16')\n",
    "retraining_model=pretrained_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# benchmark_loss, benchmark_mean_residual, benchmark_large_errors_counter =  test_loop(dataloader=benchmark_dataloader, model=retraining_model, loss_fn=criterion, large_error_threshold=LARGE_ERROR_THRESHOLD_SAMPLES)\n",
    "#\n",
    "# benchmark_loss, benchmark_mean_residual, benchmark_large_errors_counter, float(benchmark_large_errors_counter) / float(len(benchmark_dataloader))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "import seisbench.data as sbd\n",
    "import pandas as pd\n",
    "import seisbench.generate as sbg\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "# 'stead', 'geofon', 'ethz', 'iquique'\n",
    "dataset_origin = 'geofon'\n",
    "SBD_CLASSES={'ethz':sbd.ETHZ, 'geofon':sbd.GEOFON, 'iquique': sbd.Iquique, 'stead':sbd.STEAD}\n",
    "SBD_CLASS=SBD_CLASSES[dataset_origin]\n",
    "NUM_SAMPLES=3001\n",
    "PHASE_LABEL = 'P' # 'S'\n",
    "SAMPLING_RATE = 100\n",
    "SNR_THRESHOLD = 20\n",
    "BATCH_SIZE=1000\n",
    "TARGETS_PATH = f'/home/moshe/datasets/GFZ/targets/{dataset_origin}/'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def residual_to_cell(residual: float)->int:\n",
    "    return  round((residual/100) + 0.00001) + 10\n",
    "def cell_to_residual(cell: int)->int:\n",
    "    return cell - 10\n",
    "\n",
    "cell_to_residual(residual_to_cell(-150))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "    residuals_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            trace, (label, label_smoothed) = batch\n",
    "            # trace = standardize(trace)\n",
    "            pred_probs = model(trace.to(model.device))\n",
    "            if SBM_CLASS == sbm.EQTransformer:\n",
    "                # EQTransformer returns a tuple (N,Z,E)\n",
    "                pred_probs = torch.stack((pred_probs[1],pred_probs[0],pred_probs[2]), dim=0).swapaxes(0,1)\n",
    "\n",
    "            # Ignore prediction probs outside a 10-second window around the label\n",
    "            pred_probs[:,0,:(int(label)-500)]=0\n",
    "            pred_probs[:,0,(int(label)+500):]=0\n",
    "            # Take the maximum of the z channel prediction\n",
    "            loss = loss_fn(pred_probs[:,0,:], label_smoothed.to(model.device))\n",
    "            # loss = loss_fn(F.log_softmax(pred_probs[:,0,:], dim=-1), F.log_softmax(label_smoothed.to(model.device), dim=-1))\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            prediction = torch.argmax(pred_probs[:, 0, :], dim=-1)\n",
    "            residual = float(prediction - label.to(model.device))\n",
    "            residuals_list.append(residual)\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    return test_loss, residuals_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# !mkdir targets\n",
    "# !mkdir targets/ethz\n",
    "# !mkdir targets/geofon\n",
    "# !mkdir targets/iquique\n",
    "# !mkdir targets/stead\n",
    "\n",
    "# #ethz\n",
    "# !wget https://dcache-demo.desy.de:2443/Helmholtz/HelmholtzAI/SeisBench/auxiliary/pick-benchmark/targets/ethz/task1.csv\n",
    "# !wget https://dcache-demo.desy.de:2443/Helmholtz/HelmholtzAI/SeisBench/auxiliary/pick-benchmark/targets/ethz/task23.csv\n",
    "# !mv *.csv targets/ethz\n",
    "#\n",
    "# #geofon\n",
    "# !wget https://dcache-demo.desy.de:2443/Helmholtz/HelmholtzAI/SeisBench/auxiliary/pick-benchmark/targets/geofon/task1.csv\n",
    "# !wget https://dcache-demo.desy.de:2443/Helmholtz/HelmholtzAI/SeisBench/auxiliary/pick-benchmark/targets/geofon/task23.csv\n",
    "# !mv *.csv targets/geofon\n",
    "\n",
    "#iquique\n",
    "# NO TARGETS!!!!\n",
    "# !wget https://dcache-demo.desy.de:2443/Helmholtz/HelmholtzAI/SeisBench/auxiliary/pick-benchmark/targets/iquique/task1.csv\n",
    "# !wget https://dcache-demo.desy.de:2443/Helmholtz/HelmholtzAI/SeisBench/auxiliary/pick-benchmark/targets/iquique/task23.csv\n",
    "# !mv *.csv targets/iquique\n",
    "\n",
    "#stead\n",
    "# !wget https://dcache-demo.desy.de:2443/Helmholtz/HelmholtzAI/SeisBench/auxiliary/pick-benchmark/targets/stead/task1.csv\n",
    "# !wget https://dcache-demo.desy.de:2443/Helmholtz/HelmholtzAI/SeisBench/auxiliary/pick-benchmark/targets/stead/task23.csv\n",
    "# !mv *.csv targets/stead"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEOFON - 86261 traces\n"
     ]
    }
   ],
   "source": [
    "data = SBD_CLASS(sampling_rate=SAMPLING_RATE, force=True).test()\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All events will contribute to the resulting dataset\n",
      "89227\n",
      "There are 89227 traces in the resulting dataset.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "targets_task23 = pd.read_csv(os.path.join(TARGETS_PATH,'task23.csv'))\n",
    "merged_metadata = pd.merge(data.metadata, targets_task23, on='trace_name')\n",
    "requested_event_list=[]\n",
    "filtered_metadata = merged_metadata[(merged_metadata.phase_label == PHASE_LABEL) ]\n",
    "if requested_event_list:\n",
    "  filtered_metadata = filtered_metadata[filtered_metadata.source_id.isin(requested_event_list)]\n",
    "else:\n",
    "  print('All events will contribute to the resulting dataset')\n",
    "\n",
    "gen  = sbg.SteeredGenerator(data, filtered_metadata )\n",
    "print(len(gen))\n",
    "augmentations = [\n",
    "            sbg.ChangeDtype(np.float32),\n",
    "            sbg.Normalize(demean_axis=-1, amp_norm_axis=-1, amp_norm_type=\"peak\"),\n",
    "            sbg.SteeredWindow(windowlen=NUM_SAMPLES, strategy=\"pad\")\n",
    "        ]\n",
    "\n",
    "gen.add_augmentations(augmentations)\n",
    "\n",
    "@gen.augmentation\n",
    "def get_arrival_sample(state_dict):\n",
    "  _, metadata = state_dict[\"X\"]\n",
    "  key = f\"trace_{state_dict['_control_']['full_phase_label']}_arrival_sample\"\n",
    "  state_dict['station_code'] = (metadata['station_code'], key)\n",
    "  state_dict[\"onset_sample\"] = (metadata[key], None)\n",
    "\n",
    "num_dataset_traces = int(len(gen))\n",
    "\n",
    "print(f'There are {num_dataset_traces} traces in the resulting dataset.')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "loader =  DataLoader(gen, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "print(len(loader))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****   Batch No. 0   1000 traces ****\n",
      "Benchmark root mean squared residual  100.49063873291016, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 19.,  36., 894.,  28.,  23.]),\n",
      "bin_edges=tensor([-500.5999, -300.6931, -100.7863,   99.1204,  299.0272,  498.9340]))\n",
      "Retrained root mean squared residual 100.49063873291016, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 19.,  36., 894.,  28.,  23.]),\n",
      "bin_edges=tensor([-500.5999, -300.6931, -100.7863,   99.1204,  299.0272,  498.9340]))\n",
      "****   Batch No. 1   1000 traces ****\n",
      "Benchmark root mean squared residual  89.2436752319336, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  22.,   58., 1813.,   69.,   38.]),\n",
      "bin_edges=tensor([-500.8940, -300.9284, -100.9628,   99.0027,  298.9684,  498.9340]))\n",
      "Retrained root mean squared residual 89.2436752319336, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  22.,   58., 1813.,   69.,   38.]),\n",
      "bin_edges=tensor([-500.8940, -300.9284, -100.9628,   99.0027,  298.9684,  498.9340]))\n",
      "****   Batch No. 2   1000 traces ****\n",
      "Benchmark root mean squared residual  93.27483367919922, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  35.,   92., 2694.,  115.,   64.]),\n",
      "bin_edges=tensor([-500.8940, -300.9284, -100.9628,   99.0027,  298.9684,  498.9340]))\n",
      "Retrained root mean squared residual 93.27483367919922, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  35.,   92., 2694.,  115.,   64.]),\n",
      "bin_edges=tensor([-500.8940, -300.9284, -100.9628,   99.0027,  298.9684,  498.9340]))\n",
      "****   Batch No. 3   1000 traces ****\n",
      "Benchmark root mean squared residual  90.25569152832031, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  42.,  115., 3614.,  150.,   79.]),\n",
      "bin_edges=tensor([-500.8940, -300.9284, -100.9628,   99.0027,  298.9684,  498.9340]))\n",
      "Retrained root mean squared residual 90.25569152832031, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  42.,  115., 3614.,  150.,   79.]),\n",
      "bin_edges=tensor([-500.8940, -300.9284, -100.9628,   99.0027,  298.9684,  498.9340]))\n",
      "****   Batch No. 4   1000 traces ****\n",
      "Benchmark root mean squared residual  91.6037826538086, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  52.,  140., 4517.,  188.,  103.]),\n",
      "bin_edges=tensor([-500.8940, -300.9284, -100.9628,   99.0027,  298.9684,  498.9340]))\n",
      "Retrained root mean squared residual 91.6037826538086, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  52.,  140., 4517.,  188.,  103.]),\n",
      "bin_edges=tensor([-500.8940, -300.9284, -100.9628,   99.0027,  298.9684,  498.9340]))\n",
      "****   Batch No. 5   1000 traces ****\n",
      "Benchmark root mean squared residual  88.0880355834961, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  59.,  161., 5446.,  227.,  107.]),\n",
      "bin_edges=tensor([-500.8940, -300.9284, -100.9628,   99.0027,  298.9684,  498.9340]))\n",
      "Retrained root mean squared residual 88.0880355834961, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  59.,  161., 5446.,  227.,  107.]),\n",
      "bin_edges=tensor([-500.8940, -300.9284, -100.9628,   99.0027,  298.9684,  498.9340]))\n",
      "****   Batch No. 6   1000 traces ****\n",
      "Benchmark root mean squared residual  85.67056274414062, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  66.,  187., 6369.,  267.,  111.]),\n",
      "bin_edges=tensor([-500.8940, -300.9284, -100.9628,   99.0027,  298.9684,  498.9340]))\n",
      "Retrained root mean squared residual 85.67056274414062, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  66.,  187., 6369.,  267.,  111.]),\n",
      "bin_edges=tensor([-500.8940, -300.9284, -100.9628,   99.0027,  298.9684,  498.9340]))\n",
      "****   Batch No. 7   1000 traces ****\n",
      "Benchmark root mean squared residual  83.07465362548828, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  72.,  203., 7328.,  281.,  116.]),\n",
      "bin_edges=tensor([-500.8940, -300.9284, -100.9628,   99.0027,  298.9684,  498.9340]))\n",
      "Retrained root mean squared residual 83.07465362548828, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  72.,  203., 7328.,  281.,  116.]),\n",
      "bin_edges=tensor([-500.8940, -300.9284, -100.9628,   99.0027,  298.9684,  498.9340]))\n",
      "****   Batch No. 8   1000 traces ****\n",
      "Benchmark root mean squared residual  80.0892562866211, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  76.,  218., 8290.,  298.,  118.]),\n",
      "bin_edges=tensor([-500.8940, -300.9284, -100.9628,   99.0027,  298.9684,  498.9340]))\n",
      "Retrained root mean squared residual 80.0892562866211, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  76.,  218., 8290.,  298.,  118.]),\n",
      "bin_edges=tensor([-500.8940, -300.9284, -100.9628,   99.0027,  298.9684,  498.9340]))\n",
      "****   Batch No. 9   1000 traces ****\n",
      "Benchmark root mean squared residual  81.8798599243164, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  86.,  230., 9180.,  359.,  145.]),\n",
      "bin_edges=tensor([-500.8940, -300.9260, -100.9579,   99.0101,  298.9781,  498.9462]))\n",
      "Retrained root mean squared residual 81.8798599243164, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  86.,  230., 9180.,  359.,  145.]),\n",
      "bin_edges=tensor([-500.8940, -300.9260, -100.9579,   99.0101,  298.9781,  498.9462]))\n",
      "****   Batch No. 10   1000 traces ****\n",
      "Benchmark root mean squared residual  82.1873550415039, large error counters torch.return_types.histogram(\n",
      "hist=tensor([   96.,   250., 10099.,   391.,   164.]),\n",
      "bin_edges=tensor([-500.8940, -300.9260, -100.9579,   99.0101,  298.9781,  498.9462]))\n",
      "Retrained root mean squared residual 82.1873550415039, large error counters torch.return_types.histogram(\n",
      "hist=tensor([   96.,   250., 10099.,   391.,   164.]),\n",
      "bin_edges=tensor([-500.8940, -300.9260, -100.9579,   99.0101,  298.9781,  498.9462]))\n",
      "****   Batch No. 11   1000 traces ****\n",
      "Benchmark root mean squared residual  81.7845687866211, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  104.,   273., 11014.,   437.,   172.]),\n",
      "bin_edges=tensor([-500.8940, -300.9260, -100.9579,   99.0101,  298.9781,  498.9462]))\n",
      "Retrained root mean squared residual 81.7845687866211, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  104.,   273., 11014.,   437.,   172.]),\n",
      "bin_edges=tensor([-500.8940, -300.9260, -100.9579,   99.0101,  298.9781,  498.9462]))\n",
      "****   Batch No. 12   1000 traces ****\n",
      "Benchmark root mean squared residual  80.19904327392578, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  105.,   297., 11955.,   466.,   177.]),\n",
      "bin_edges=tensor([-500.8940, -300.9260, -100.9579,   99.0101,  298.9781,  498.9462]))\n",
      "Retrained root mean squared residual 80.19904327392578, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  105.,   297., 11955.,   466.,   177.]),\n",
      "bin_edges=tensor([-500.8940, -300.9260, -100.9579,   99.0101,  298.9781,  498.9462]))\n",
      "****   Batch No. 13   1000 traces ****\n",
      "Benchmark root mean squared residual  80.28186798095703, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  115.,   322., 12858.,   517.,   188.]),\n",
      "bin_edges=tensor([-500.8940, -300.9260, -100.9579,   99.0101,  298.9781,  498.9462]))\n",
      "Retrained root mean squared residual 80.28186798095703, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  115.,   322., 12858.,   517.,   188.]),\n",
      "bin_edges=tensor([-500.8940, -300.9260, -100.9579,   99.0101,  298.9781,  498.9462]))\n",
      "****   Batch No. 14   1000 traces ****\n",
      "Benchmark root mean squared residual  78.3400650024414, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  115.,   326., 13832.,   534.,   193.]),\n",
      "bin_edges=tensor([-500.8940, -300.9260, -100.9579,   99.0101,  298.9781,  498.9462]))\n",
      "Retrained root mean squared residual 78.3400650024414, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  115.,   326., 13832.,   534.,   193.]),\n",
      "bin_edges=tensor([-500.8940, -300.9260, -100.9579,   99.0101,  298.9781,  498.9462]))\n",
      "****   Batch No. 15   1000 traces ****\n",
      "Benchmark root mean squared residual  77.2102279663086, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  121.,   337., 14793.,   550.,   199.]),\n",
      "bin_edges=tensor([-500.8940, -300.9260, -100.9579,   99.0101,  298.9781,  498.9462]))\n",
      "Retrained root mean squared residual 77.2102279663086, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  121.,   337., 14793.,   550.,   199.]),\n",
      "bin_edges=tensor([-500.8940, -300.9260, -100.9579,   99.0101,  298.9781,  498.9462]))\n",
      "****   Batch No. 16   1000 traces ****\n",
      "Benchmark root mean squared residual  77.2247085571289, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  124.,   366., 15684.,   614.,   212.]),\n",
      "bin_edges=tensor([-500.8940, -300.9260, -100.9579,   99.0101,  298.9781,  498.9462]))\n",
      "Retrained root mean squared residual 77.2247085571289, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  124.,   366., 15684.,   614.,   212.]),\n",
      "bin_edges=tensor([-500.8940, -300.9260, -100.9579,   99.0101,  298.9781,  498.9462]))\n",
      "****   Batch No. 17   1000 traces ****\n",
      "Benchmark root mean squared residual  78.31745147705078, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  141.,   392., 16581.,   661.,   225.]),\n",
      "bin_edges=tensor([-500.9999, -301.0107, -101.0215,   98.9677,  298.9570,  498.9462]))\n",
      "Retrained root mean squared residual 78.31745147705078, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  141.,   392., 16581.,   661.,   225.]),\n",
      "bin_edges=tensor([-500.9999, -301.0107, -101.0215,   98.9677,  298.9570,  498.9462]))\n",
      "****   Batch No. 18   1000 traces ****\n",
      "Benchmark root mean squared residual  78.6021499633789, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  152.,   410., 17497.,   706.,   235.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "Retrained root mean squared residual 78.6021499633789, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  152.,   410., 17497.,   706.,   235.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "****   Batch No. 19   1000 traces ****\n",
      "Benchmark root mean squared residual  78.03624725341797, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  159.,   432., 18437.,   729.,   243.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "Retrained root mean squared residual 78.03624725341797, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  159.,   432., 18437.,   729.,   243.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "****   Batch No. 20   1000 traces ****\n",
      "Benchmark root mean squared residual  77.88518524169922, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  170.,   451., 19367.,   759.,   253.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "Retrained root mean squared residual 77.88518524169922, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  170.,   451., 19367.,   759.,   253.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "****   Batch No. 21   1000 traces ****\n",
      "Benchmark root mean squared residual  77.70298767089844, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  180.,   472., 20297.,   790.,   261.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "Retrained root mean squared residual 77.70298767089844, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  180.,   472., 20297.,   790.,   261.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "****   Batch No. 22   1000 traces ****\n",
      "Benchmark root mean squared residual  78.36495208740234, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  195.,   492., 21205.,   835.,   273.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "Retrained root mean squared residual 78.36495208740234, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  195.,   492., 21205.,   835.,   273.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "****   Batch No. 23   1000 traces ****\n",
      "Benchmark root mean squared residual  78.49124145507812, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  206.,   516., 22129.,   865.,   284.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "Retrained root mean squared residual 78.49124145507812, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  206.,   516., 22129.,   865.,   284.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "****   Batch No. 24   1000 traces ****\n",
      "Benchmark root mean squared residual  80.74422454833984, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  238.,   555., 22931.,   961.,   315.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "Retrained root mean squared residual 80.74422454833984, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  238.,   555., 22931.,   961.,   315.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "****   Batch No. 25   1000 traces ****\n",
      "Benchmark root mean squared residual  80.6297836303711, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  254.,   571., 23863.,   991.,   321.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "Retrained root mean squared residual 80.6297836303711, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  254.,   571., 23863.,   991.,   321.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "****   Batch No. 26   1000 traces ****\n",
      "Benchmark root mean squared residual  82.00727081298828, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  271.,   595., 24743.,  1040.,   351.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "Retrained root mean squared residual 82.00727081298828, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  271.,   595., 24743.,  1040.,   351.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "****   Batch No. 27   1000 traces ****\n",
      "Benchmark root mean squared residual  82.5699234008789, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  281.,   626., 25627.,  1092.,   374.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "Retrained root mean squared residual 82.5699234008789, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  281.,   626., 25627.,  1092.,   374.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "****   Batch No. 28   1000 traces ****\n",
      "Benchmark root mean squared residual  81.69944763183594, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  282.,   646., 26577.,  1117.,   378.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "Retrained root mean squared residual 81.69944763183594, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  282.,   646., 26577.,  1117.,   378.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "****   Batch No. 29   1000 traces ****\n",
      "Benchmark root mean squared residual  81.23043060302734, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  285.,   659., 27527.,  1139.,   390.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "Retrained root mean squared residual 81.23043060302734, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  285.,   659., 27527.,  1139.,   390.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "****   Batch No. 30   1000 traces ****\n",
      "Benchmark root mean squared residual  80.50678253173828, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  297.,   662., 28506.,  1143.,   392.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "Retrained root mean squared residual 80.50678253173828, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  297.,   662., 28506.,  1143.,   392.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "****   Batch No. 31   1000 traces ****\n",
      "Benchmark root mean squared residual  82.16266632080078, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  326.,   708., 29340.,  1208.,   418.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "Retrained root mean squared residual 82.16266632080078, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  326.,   708., 29340.,  1208.,   418.]),\n",
      "bin_edges=tensor([-500.9999, -301.0047, -101.0096,   98.9856,  298.9808,  498.9760]))\n",
      "****   Batch No. 32   1000 traces ****\n",
      "Benchmark root mean squared residual  81.87681579589844, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  332.,   727., 30266.,  1247.,   428.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 81.87681579589844, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  332.,   727., 30266.,  1247.,   428.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 33   1000 traces ****\n",
      "Benchmark root mean squared residual  81.4150161743164, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  337.,   744., 31197.,  1287.,   435.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 81.4150161743164, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  337.,   744., 31197.,  1287.,   435.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 34   1000 traces ****\n",
      "Benchmark root mean squared residual  81.72413635253906, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  363.,   776., 32103.,  1316.,   442.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 81.72413635253906, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  363.,   776., 32103.,  1316.,   442.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 35   1000 traces ****\n",
      "Benchmark root mean squared residual  81.22905731201172, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  370.,   789., 33057.,  1335.,   449.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 81.22905731201172, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  370.,   789., 33057.,  1335.,   449.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 36   1000 traces ****\n",
      "Benchmark root mean squared residual  81.36548614501953, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  384.,   832., 33938.,  1389.,   457.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 81.36548614501953, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  384.,   832., 33938.,  1389.,   457.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 37   1000 traces ****\n",
      "Benchmark root mean squared residual  81.289794921875, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  389.,   858., 34845.,  1440.,   468.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 81.289794921875, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  389.,   858., 34845.,  1440.,   468.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 38   1000 traces ****\n",
      "Benchmark root mean squared residual  81.14607238769531, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  394.,   883., 35774.,  1469.,   480.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 81.14607238769531, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  394.,   883., 35774.,  1469.,   480.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 39   1000 traces ****\n",
      "Benchmark root mean squared residual  81.0694808959961, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  404.,   898., 36678.,  1530.,   490.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 81.0694808959961, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  404.,   898., 36678.,  1530.,   490.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 40   1000 traces ****\n",
      "Benchmark root mean squared residual  81.05594635009766, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  415.,   931., 37589.,  1562.,   503.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 81.05594635009766, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  415.,   931., 37589.,  1562.,   503.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 41   1000 traces ****\n",
      "Benchmark root mean squared residual  82.62960052490234, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  442.,   972., 38388.,  1653.,   545.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 82.62960052490234, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  442.,   972., 38388.,  1653.,   545.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 42   1000 traces ****\n",
      "Benchmark root mean squared residual  82.94105529785156, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  447.,   991., 39238.,  1764.,   560.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 82.94105529785156, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  447.,   991., 39238.,  1764.,   560.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 43   1000 traces ****\n",
      "Benchmark root mean squared residual  82.74857330322266, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  457.,  1024., 40157.,  1794.,   568.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 82.74857330322266, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  457.,  1024., 40157.,  1794.,   568.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 44   1000 traces ****\n",
      "Benchmark root mean squared residual  82.73388671875, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  469.,  1051., 41085.,  1814.,   581.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 82.73388671875, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  469.,  1051., 41085.,  1814.,   581.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 45   1000 traces ****\n",
      "Benchmark root mean squared residual  82.44116973876953, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  472.,  1068., 41993.,  1878.,   589.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 82.44116973876953, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  472.,  1068., 41993.,  1878.,   589.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 46   1000 traces ****\n",
      "Benchmark root mean squared residual  83.13801574707031, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  496.,  1123., 42814.,  1959.,   608.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 83.13801574707031, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  496.,  1123., 42814.,  1959.,   608.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 47   1000 traces ****\n",
      "Benchmark root mean squared residual  83.38252258300781, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  537.,  1134., 43724.,  1990.,   615.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 83.38252258300781, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  537.,  1134., 43724.,  1990.,   615.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 48   1000 traces ****\n",
      "Benchmark root mean squared residual  83.61582946777344, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  560.,  1176., 44589.,  2050.,   625.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 83.61582946777344, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  560.,  1176., 44589.,  2050.,   625.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 49   1000 traces ****\n",
      "Benchmark root mean squared residual  83.99260711669922, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  573.,  1199., 45458.,  2120.,   650.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 83.99260711669922, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  573.,  1199., 45458.,  2120.,   650.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 50   1000 traces ****\n",
      "Benchmark root mean squared residual  84.64396667480469, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  593.,  1228., 46298.,  2207.,   674.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 84.64396667480469, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  593.,  1228., 46298.,  2207.,   674.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 51   1000 traces ****\n",
      "Benchmark root mean squared residual  84.76225280761719, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  609.,  1262., 47196.,  2242.,   691.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 84.76225280761719, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  609.,  1262., 47196.,  2242.,   691.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 52   1000 traces ****\n",
      "Benchmark root mean squared residual  84.9599380493164, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  632.,  1283., 48099.,  2279.,   707.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 84.9599380493164, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  632.,  1283., 48099.,  2279.,   707.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 53   1000 traces ****\n",
      "Benchmark root mean squared residual  84.74119567871094, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  634.,  1304., 49006.,  2336.,   720.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 84.74119567871094, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  634.,  1304., 49006.,  2336.,   720.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 54   1000 traces ****\n",
      "Benchmark root mean squared residual  84.30220794677734, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  641.,  1313., 49955.,  2368.,   723.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 84.30220794677734, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  641.,  1313., 49955.,  2368.,   723.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 55   1000 traces ****\n",
      "Benchmark root mean squared residual  84.27268981933594, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  645.,  1331., 50861.,  2421.,   742.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 84.27268981933594, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  645.,  1331., 50861.,  2421.,   742.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 56   1000 traces ****\n",
      "Benchmark root mean squared residual  84.66043090820312, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  663.,  1395., 51701.,  2480.,   761.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 84.66043090820312, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  663.,  1395., 51701.,  2480.,   761.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 57   1000 traces ****\n",
      "Benchmark root mean squared residual  84.90586853027344, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  678.,  1429., 52575.,  2539.,   779.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 84.90586853027344, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  678.,  1429., 52575.,  2539.,   779.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 58   1000 traces ****\n",
      "Benchmark root mean squared residual  85.3557357788086, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  693.,  1456., 53455.,  2582.,   814.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 85.3557357788086, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  693.,  1456., 53455.,  2582.,   814.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 59   1000 traces ****\n",
      "Benchmark root mean squared residual  85.98914337158203, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  722.,  1489., 54318.,  2630.,   841.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 85.98914337158203, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  722.,  1489., 54318.,  2630.,   841.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 60   1000 traces ****\n",
      "Benchmark root mean squared residual  85.75556945800781, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  732.,  1503., 55257.,  2660.,   848.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 85.75556945800781, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  732.,  1503., 55257.,  2660.,   848.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 61   1000 traces ****\n",
      "Benchmark root mean squared residual  85.85340118408203, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  744.,  1531., 56161.,  2694.,   870.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 85.85340118408203, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  744.,  1531., 56161.,  2694.,   870.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 62   1000 traces ****\n",
      "Benchmark root mean squared residual  86.05757904052734, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  768.,  1549., 57063.,  2737.,   883.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 86.05757904052734, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  768.,  1549., 57063.,  2737.,   883.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 63   1000 traces ****\n",
      "Benchmark root mean squared residual  86.33956146240234, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  789.,  1576., 57952.,  2782.,   901.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 86.33956146240234, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  789.,  1576., 57952.,  2782.,   901.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 64   1000 traces ****\n",
      "Benchmark root mean squared residual  86.48947143554688, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  791.,  1611., 58829.,  2837.,   932.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 86.48947143554688, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  791.,  1611., 58829.,  2837.,   932.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 65   1000 traces ****\n",
      "Benchmark root mean squared residual  86.53370666503906, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  811.,  1646., 59721.,  2881.,   941.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 86.53370666503906, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  811.,  1646., 59721.,  2881.,   941.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 66   1000 traces ****\n",
      "Benchmark root mean squared residual  86.30166625976562, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  817.,  1661., 60647.,  2926.,   949.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 86.30166625976562, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  817.,  1661., 60647.,  2926.,   949.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 67   1000 traces ****\n",
      "Benchmark root mean squared residual  87.56903839111328, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  836.,  1701., 61402.,  3039.,  1022.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 87.56903839111328, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  836.,  1701., 61402.,  3039.,  1022.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 68   1000 traces ****\n",
      "Benchmark root mean squared residual  87.5881118774414, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  839.,  1715., 62301.,  3101.,  1044.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 87.5881118774414, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  839.,  1715., 62301.,  3101.,  1044.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 69   1000 traces ****\n",
      "Benchmark root mean squared residual  87.76097869873047, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  856.,  1735., 63201.,  3141.,  1067.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 87.76097869873047, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  856.,  1735., 63201.,  3141.,  1067.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 70   1000 traces ****\n",
      "Benchmark root mean squared residual  87.86983489990234, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  874.,  1751., 64104.,  3186.,  1085.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 87.86983489990234, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  874.,  1751., 64104.,  3186.,  1085.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 71   1000 traces ****\n",
      "Benchmark root mean squared residual  88.30998992919922, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  911.,  1775., 65006.,  3209.,  1099.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 88.30998992919922, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  911.,  1775., 65006.,  3209.,  1099.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 72   1000 traces ****\n",
      "Benchmark root mean squared residual  89.16924285888672, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  920.,  1829., 65772.,  3321.,  1158.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 89.16924285888672, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  920.,  1829., 65772.,  3321.,  1158.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 73   1000 traces ****\n",
      "Benchmark root mean squared residual  88.98261260986328, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  935.,  1846., 66715.,  3337.,  1167.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 88.98261260986328, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  935.,  1846., 66715.,  3337.,  1167.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 74   1000 traces ****\n",
      "Benchmark root mean squared residual  89.02922058105469, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  948.,  1864., 67602.,  3404.,  1182.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 89.02922058105469, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  948.,  1864., 67602.,  3404.,  1182.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 75   1000 traces ****\n",
      "Benchmark root mean squared residual  88.86769104003906, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  956.,  1875., 68537.,  3438.,  1194.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 88.86769104003906, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  956.,  1875., 68537.,  3438.,  1194.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 76   1000 traces ****\n",
      "Benchmark root mean squared residual  89.44860076904297, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  978.,  1902., 69392.,  3484.,  1244.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 89.44860076904297, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  978.,  1902., 69392.,  3484.,  1244.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 77   1000 traces ****\n",
      "Benchmark root mean squared residual  89.5286636352539, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  993.,  1937., 70270.,  3539.,  1261.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 89.5286636352539, large error counters torch.return_types.histogram(\n",
      "hist=tensor([  993.,  1937., 70270.,  3539.,  1261.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 78   1000 traces ****\n",
      "Benchmark root mean squared residual  89.57586669921875, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1008.,  1964., 71159.,  3596.,  1273.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 89.57586669921875, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1008.,  1964., 71159.,  3596.,  1273.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 79   1000 traces ****\n",
      "Benchmark root mean squared residual  89.93488311767578, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1019.,  1998., 72017.,  3652.,  1314.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 89.93488311767578, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1019.,  1998., 72017.,  3652.,  1314.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 80   1000 traces ****\n",
      "Benchmark root mean squared residual  90.05628204345703, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1028.,  2028., 72877.,  3733.,  1334.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 90.05628204345703, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1028.,  2028., 72877.,  3733.,  1334.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 81   1000 traces ****\n",
      "Benchmark root mean squared residual  90.13582611083984, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1044.,  2046., 73773.,  3784.,  1353.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 90.13582611083984, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1044.,  2046., 73773.,  3784.,  1353.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 82   1000 traces ****\n",
      "Benchmark root mean squared residual  90.14075469970703, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1054.,  2073., 74646.,  3864.,  1363.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 90.14075469970703, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1054.,  2073., 74646.,  3864.,  1363.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 83   1000 traces ****\n",
      "Benchmark root mean squared residual  90.8956069946289, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1082.,  2131., 75412.,  3961.,  1414.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 90.8956069946289, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1082.,  2131., 75412.,  3961.,  1414.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 84   1000 traces ****\n",
      "Benchmark root mean squared residual  90.8184585571289, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1092.,  2146., 76331.,  4001.,  1430.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 90.8184585571289, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1092.,  2146., 76331.,  4001.,  1430.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 85   1000 traces ****\n",
      "Benchmark root mean squared residual  90.66400909423828, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1101.,  2168., 77258.,  4032.,  1441.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 90.66400909423828, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1101.,  2168., 77258.,  4032.,  1441.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 86   1000 traces ****\n",
      "Benchmark root mean squared residual  90.53275299072266, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1111.,  2199., 78174.,  4061.,  1455.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 90.53275299072266, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1111.,  2199., 78174.,  4061.,  1455.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 87   1000 traces ****\n",
      "Benchmark root mean squared residual  90.61920166015625, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1125.,  2230., 79057.,  4109.,  1479.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 90.61920166015625, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1125.,  2230., 79057.,  4109.,  1479.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 88   1000 traces ****\n",
      "Benchmark root mean squared residual  90.87866973876953, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1136.,  2255., 79929.,  4166.,  1514.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 90.87866973876953, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1136.,  2255., 79929.,  4166.,  1514.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "****   Batch No. 89   227 traces ****\n",
      "Benchmark root mean squared residual  90.87448120117188, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1137.,  2257., 80130.,  4183.,  1520.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "Retrained root mean squared residual 90.87448120117188, large error counters torch.return_types.histogram(\n",
      "hist=tensor([ 1137.,  2257., 80130.,  4183.,  1520.]),\n",
      "bin_edges=tensor([-500.9999, -301.0021, -101.0044,   98.9933,  298.9910,  498.9888]))\n",
      "EVALUATION FINISHED 89227 traces\n",
      "Benchmark root mean squared residual  90.87448120117188, median 1.89404296875 \n",
      "Retrained root mean squared residual 90.87448120117188, median 1.89404296875 \n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.patches.StepPatch at 0x7f0a5e6ab880>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum_traces, sum_benchmark_loss, sum_benchmark_mean_residual,  sum_retrained_loss, sum_retrained_mean_residual = 0,0,0,0,0\n",
    "num_thresholds = 20\n",
    "le_thresholds = list(range(100,100*num_thresholds + 1,100))\n",
    "benchmark_residuals_list = []\n",
    "retrained_residuals_list = []\n",
    "sum_retrained_large_errors_counters = {th:0 for th in le_thresholds}\n",
    "for batch_idx, dataset_dict in enumerate(loader):\n",
    "\n",
    "    traces=dataset_dict['X']\n",
    "    labels = dataset_dict['onset_sample']\n",
    "\n",
    "    criterion = loss_fn\n",
    "\n",
    "    valset_original = CustomDataset(dataset=traces.float(), labels=labels.float(), target_transform=lambda l: (l,label_normal_smooth(l)))\n",
    "\n",
    "    benchmark_dataloader = DataLoader(valset_original, batch_size=1, shuffle=False)\n",
    "\n",
    "    benchmark_loss, batch_benchmark_residuals_list =  evaluate_loop(dataloader=benchmark_dataloader, model=pretrained_model, loss_fn=criterion)\n",
    "                                                                                              # large_error_threshold=LARGE_ERROR_THRESHOLD_SAMPLES)\n",
    "    retrained_loss, batch_retrained_residuals_list =  evaluate_loop(dataloader=benchmark_dataloader, model=retraining_model, loss_fn=criterion)\n",
    "                                                                                              # large_error_threshold=LARGE_ERROR_THRESHOLD_SAMPLES)\n",
    "\n",
    "    benchmark_residuals_list.extend(batch_benchmark_residuals_list)\n",
    "    retrained_residuals_list.extend(batch_retrained_residuals_list)\n",
    "    benchmark_residual_tensor =   torch.tensor(benchmark_residuals_list)\n",
    "    benchmark_residuals_rmse = torch.sqrt(torch.mean(torch.square(benchmark_residual_tensor)))\n",
    "    benchmark_residual_median = torch.median(benchmark_residual_tensor)\n",
    "    retrained_residual_tensor =  torch.tensor(retrained_residuals_list)\n",
    "    retrained_residuals_rmse = torch.sqrt(torch.mean(torch.square(retrained_residual_tensor)))\n",
    "    retrained_residuals_median = torch.median(retrained_residual_tensor)\n",
    "\n",
    "\n",
    "\n",
    "    print(f'****   Batch No. {batch_idx}   {traces.shape[0]} traces ****')\n",
    "    print(f'Benchmark root mean squared residual  {benchmark_residuals_rmse}, large error counters {torch.histogram(benchmark_residual_tensor, bins=5)}')\n",
    "    print(f'Retrained root mean squared residual {retrained_residuals_rmse}, large error counters {torch.histogram(retrained_residual_tensor, bins=5)}')\n",
    "    sum_traces+=traces.shape[0]\n",
    "\n",
    "print('EVALUATION FINISHED', sum_traces, 'traces')\n",
    "\n",
    "benchmark_residual_tensor =   torch.tensor(benchmark_residuals_list)\n",
    "benchmark_residuals_rmse = torch.sqrt(torch.mean(torch.square(benchmark_residual_tensor)))\n",
    "benchmark_residual_median = torch.median(benchmark_residual_tensor)\n",
    "retrained_residual_tensor =  torch.tensor(retrained_residuals_list)\n",
    "retrained_residuals_rmse = torch.sqrt(torch.mean(torch.square(retrained_residual_tensor)))\n",
    "retrained_residuals_median = torch.median(retrained_residual_tensor)\n",
    "print(f'Benchmark root mean squared residual  {benchmark_residuals_rmse}, median {benchmark_residual_median} ')\n",
    "print(f'Retrained root mean squared residual {retrained_residuals_rmse}, median {retrained_residuals_median} ')\n",
    "\n",
    "benchmark_hist, benchmark_bins = torch.histogram(benchmark_residual_tensor, bins=30)\n",
    "retrained_hist, retrained_bins = torch.histogram(retrained_residual_tensor, bins=30)\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(12,8))\n",
    "ax1.set_title('Benchmark Model Residuals')\n",
    "ax2.set_title('Retrained Model Residuals')\n",
    "ax1.stairs(benchmark_hist, benchmark_bins)\n",
    "ax2.stairs(retrained_hist, retrained_bins)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.patches.StepPatch at 0x7f0a5e4c1d80>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "benchmark_hist, benchmark_bins = torch.histogram(benchmark_residual_tensor, bins=10)\n",
    "retrained_hist, retrained_bins = torch.histogram(retrained_residual_tensor, bins=10)\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(12,8), sharey='all', sharex='all')\n",
    "ax1.set_title('Benchmark Model Residuals')\n",
    "ax2.set_title('Retrained Model Residuals')\n",
    "ax1.stairs(benchmark_hist, benchmark_bins)\n",
    "ax2.stairs(retrained_hist, retrained_bins)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# print(sum_benchmark_large_errors_counters.values())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# print(sum_retrained_large_errors_counters.values())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2) = plt.subplots(1,2, sharey='all', figsize=(12,8))\n",
    "# ax1.stairs(list(sum_benchmark_large_errors_counters.values()),list(sum_benchmark_large_errors_counters.keys())+[1100]);\n",
    "# ax1.set_title('Pretrained - Benchmark')\n",
    "# ax2.stairs(list(sum_retrained_large_errors_counters.values()),list(sum_retrained_large_errors_counters.keys())+[1100]);\n",
    "# ax2.set_title('Retrained')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# sum_benchmark_loss/sum_traces,  sum_retrained_loss/sum_traces"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# sum_benchmark_mean_residual/len(loader), sum_retrained_mean_residual/len(loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# len(loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# sum_benchmark_large_errors_counter*100/sum_traces,  sum_retrained_large_errors_counter*100/sum_traces"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# stead_data = sbd.STEAD(sampling_rate=SAMPLING_RATE, force=True).test()\n",
    "# print(stead_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# le_original_dataset_path = os.path.join(DATASET_PATH, 'le_original_dataset.pt')\n",
    "# assert_path_exists(path_str=le_original_dataset_path)\n",
    "# le_original_labels_path = os.path.join(DATASET_PATH, 'le_original_labels.pt')\n",
    "# assert_path_exists(path_str=le_original_labels_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# le_original_dataset, le_original_labels = load_dataset_and_labels(dataset_path=le_original_dataset_path, labels_path=le_original_labels_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# print(f'Loaded {le_original_dataset.shape[0]} traces')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
